name: Scrape Earnings Data

on:
  schedule:
    # Run daily at 6 AM UTC (1 AM EST / 10 PM PST)
    - cron: '0 6 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape-watchlist-earnings:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: earnings-tracker/scripts/node_modules
          key: ${{ runner.os }}-node-${{ hashFiles('earnings-tracker/scripts/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-
      
      - name: Install Chrome dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            chromium-browser \
            libgbm1 \
            libasound2 \
            libatk1.0-0 \
            libatk-bridge2.0-0 \
            libcups2 \
            libdrm2 \
            libgtk-3-0 \
            libnspr4 \
            libnss3 \
            libxcomposite1 \
            libxdamage1 \
            libxfixes3 \
            libxrandr2 \
            libxss1 \
            libxtst6 \
            fonts-liberation \
            libappindicator3-1 \
            xdg-utils
      
      - name: Install dependencies
        working-directory: earnings-tracker/scripts
        env:
          PUPPETEER_SKIP_DOWNLOAD: true
        run: npm install
      
      - name: Check watchlist stocks
        working-directory: earnings-tracker/scripts
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "Checking which stocks are in watchlists..."
          node -e "
          const { createClient } = require('@supabase/supabase-js');
          const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);
          
          async function checkWatchlists() {
            const { data, count } = await supabase
              .from('watchlist_stocks')
              .select('*', { count: 'exact', head: true });
            
            console.log(\`Total stocks in all watchlists: \${count || 0}\`);
            
            if (!count || count === 0) {
              console.log('⚠️  WARNING: No stocks found in any watchlists!');
              console.log('The scraper will not fetch any data.');
              console.log('Add stocks to watchlists before running the scraper.');
            }
          }
          
          checkWatchlists().catch(console.error);
          "
      
      - name: Test Chrome launch
        working-directory: earnings-tracker/scripts
        env:
          PUPPETEER_EXECUTABLE_PATH: /usr/bin/chromium-browser
          PUPPETEER_SKIP_DOWNLOAD: true
          CI: true
        run: |
          echo "Testing Chrome/Chromium launch..."
          node test-chrome-launch.js
      
      - name: Cleanup past earnings dates
        working-directory: earnings-tracker/scripts
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "Cleaning up past earnings dates..."
          node cleanup-past-earnings.js
      
      - name: Run earnings scraper (watchlist only)
        working-directory: earnings-tracker/scripts
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          PUPPETEER_EXECUTABLE_PATH: /usr/bin/chromium-browser
          PUPPETEER_SKIP_DOWNLOAD: true
        run: node scrape-watchlist-with-sec.js
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: scraper-logs
          path: earnings-tracker/scripts/logs/
          retention-days: 7

  # Summary report after scraping
  summary-report:
    needs: scrape-watchlist-earnings
    runs-on: ubuntu-latest
    if: success()
    
    steps:
      - name: Generate summary
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "## Earnings Scraper Summary"
          echo "Date: $(date)"
          echo ""
          echo "✅ Scraper completed successfully"
          echo ""
          echo "Only stocks in user watchlists were processed."

  # Optional: Send notification on failure
  notify-failure:
    needs: scrape-watchlist-earnings
    runs-on: ubuntu-latest
    if: failure()
    
    steps:
      - name: Send failure notification
        run: |
          echo "❌ Earnings scraper failed at $(date)"
          echo "Check the GitHub Actions logs for details"
          # Add your notification logic here (email, Slack, etc.)